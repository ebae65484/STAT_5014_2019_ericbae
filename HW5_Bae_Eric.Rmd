---
title: "Homework 5"
author: "Eric Bae"
date: "`r Sys.Date()`"
output:
  html_notebook:
    df_print: paged
  pdf_document: default
  html_document:
    df_print: paged
subtitle: Due October 2, 2019
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
    knitr::opts_chunk$set(echo = TRUE)
    knitr::opts_chunk$set(echo = F, eval=T, cache=T, tidy.opts=list(width.cutoff=55),
                tidy=F, include=FALSE, message=F, warning=F)
```

For each assignment, turn in by the due date/time.  Late assignments must be arranged prior to submission.  In every case, assignments are to be typed neatly using proper English in Markdown.  

This week, we spoke about R's dual handling of vectors and matrices. In this homework, we will use this duality to our advantage to both simplify our code and perhaps speed up computation.

## Problem 1

Not a swirl problem.  :)

New this week, please create a new R *Notebook* file within the project folder within the "06_vector_matrix_dual_math_speed" subfolder (file-->new-->R Notebook-->save as.  This time we will knit to html.

The filename should be: HW6_lastname_firstname, i.e. for me it would be HW6_Settlage_Bob

You will use this new R Notebook file to solve the following problems:

## Problem 2: Sums of Squares

One basic and recurring theme you will hear in statistics is "sums of squares".  Sums of squares error, regression, total, ...

In this problem, we will calculate sums of squares total using:

a. a for loop to iterate through all data points calculating the summed squared difference between the data points and mean of the data.

```{r ss_a, echo=T, eval=T, include=T}
# Given data set
set.seed(12345)
y <- seq(from=1, to=100, length.out = 1e8) + rnorm(1e8)
#y <- seq(from=1, to=100, length.out = 1e4) + rnorm(1e4) # Used for testing

# Necessary information to generate Y_hat values
y_bar <- mean(y)
sum_sq <- rep(NA, length(y))

# For Loop
system.time({
  for (i in 1:length(y)) {
  sum_sq[i] <- (y[i] - y_bar)^2
  }
  sum_sq <- sum(sum_sq)
  end_time <- system.time({})
  print(sum_sq)
})
```

&nbsp; 

b. repeat part a, but use vector operations to effect the same computation

In both cases, wrap the code in "system.time({})".  You should report the final answer and timings for both a and b.

To generate the data, use:

```{r ss_b, echo=T, eval=T, include=T}
system.time({
  sum_sq <- t(y - mean(y)) %*% (y - mean(y))
  print(sum_sq)
})
```

***

### My Answer:

The sum of square was 817,7470,3375.  

The system time for part (a), the for loop, was:  

User: 11.72  
System: 0.36  
Elapsed: 12.10.  

and the system time for part (b), the vector, was:  

User: 0.00  
System: 0.00  
Elapsed: 0.03.  

It is apparent that the vector took much less time than the for loop.  

***

&nbsp; 

## Problem 3: Using the dual nature to our advantage

As above, sometimes using a mixture of true matrix math plus component operations cleans up our code giving better readibility.  Suppose we wanted to form the following computation:

\begin{itemize}
    \item $while(abs(\Theta_0^{i}-\Theta_0^{i-1}) \text{ AND } abs(\Theta_1^{i}-\Theta_1^{i-1}) > tolerance) \text{ \{ }$
    \begin{eqnarray*}
        \Theta_0^i &=& \Theta_0^{i-1} - \alpha\frac{1}{m}\sum_{i=1}^{m} (h_0(x_i) -y_i)  \\
        \Theta_1^i &=& \Theta_1^{i-1} - \alpha\frac{1}{m}\sum_{i=1}^{m} ((h_0(x_i) -y_i)x_i) 
    \end{eqnarray*}
    $\text{ \} }$
\end{itemize}

Where $h_0(x) = \Theta_0 + \Theta_1x$.  

Given $\mathbf{X}$ and $\vec{h}$ below, implement the above algorithm and compare the results with lm(h~0+$\mathbf{X}$).  State the tolerance used and the step size, $\alpha$.

```{r eval=T, echo=T, include=T}
    set.seed(1256)
    theta <- as.matrix(c(1,2),nrow=2)
    X <- cbind(1,rep(1:10,10))
    h <- X%*%theta+rnorm(100,0,0.2)
```

***

### My Answer: 

```{r eval = T, echo = T, include = T}
# Comparison to lm function
summary(lm(h ~ 0 + X))

# My iteration loop
alpha <- 0.05
tolerance <- 1e-6
old_theta <- as.matrix(c(4, 4), nrow = 2)
new_theta <- solve(t(X)%*%X, t(X)%*%h)
h0 <- X%*%new_theta
m <- nrow(X)
iter <- 0

while ((abs(new_theta[1,] - old_theta[1,]) & 
        abs(new_theta[2,] - old_theta[2,])) > tolerance) {
  old_theta <- new_theta
  new_theta <- old_theta - alpha/m*as.matrix(c(sum(h0 - h), sum(X[,2]*(h0 - h))), nrow = 2)
  h0 <- X%*%new_theta
  iter <- iter + 1
  print(iter)
}
```

I defined my tolerance level as $1e-6$. Doing so resulted in my $\hat{\Theta}_0 \approx 0.9695$ and $\hat{\Theta}_1 \approx 2.0016$.  

My $\alpha$, the step size, was 0.05.  

These outputs were basically identical to that of the lm function.  

***

&nbsp; 

## Problem 4: Inverting matrices

Ok, so John Cook makes some good points, but if you want to do:

\begin{equation*}
\hat\beta = (X'X)^{-1}X'\underline{y}
\end{equation*}

what are you to do??  Can you explain what is going on?

***

### My Answer: 

```{r, eval = F, echo = T, include= T}
X <- cbind(rep(1, 1e5), rnorm(1e5, 5, 4))
Y <- rnorm(1e5, 8, 7)

# Using solve as inverse matrix
system.time({
  print(solve(t(X) %*% X) %*% t(X) %*% Y)
})

# vs. 

# Using solve as X'X b = X'y, which simplifies X'X and X'y first
system.time({
  print(solve(t(X) %*% X, t(X) %*% Y))
})
```

What we could do is instead of solving directly for $\hat{\beta} = (X'X)^{-1}X'y$, we could use $X'X \hat{\beta} = X'y$, which would simplify $X'X$ and $X'y$ respectively first, then do the calculation.  

The system.time() function shows that using inverted matrix gives us the time of  

User: 0.02  
System: 0.00  
Elapsed: 1.22.  

whereas simplifying matrices first before inverting gives us the time of  

User: 0.04  
System: 0.01  
Elapsed: 0.20.  

which is an improvement.  

***

&nbsp; 

## Problem 5: Need for speed challenge

In this problem, we are looking to compute the following:

\begin{equation}
y = p + A B^{-1} (q - r)
\end{equation}

Where A, B, p, q and r are formed by:

```{r data, echo=T, eval=T, include=T}
    set.seed(12456) 
    
    G <- matrix(sample(c(0,0.5,1),size=16000,replace=T),ncol=10)
    R <- cor(G) # R: 10 * 10 correlation matrix of G
    C <- kronecker(R, diag(1600)) # C is a 16000 * 16000 block diagonal matrix
    id <- sample(1:16000,size=932,replace=F)
    q <- sample(c(0,0.5,1),size=15068,replace=T) # vector of length 15068
    A <- C[id, -id] # matrix of dimension 932 * 15068
    B <- C[-id, -id] # matrix of dimension 15068 * 15068
    p <- runif(932,0,1)
    r <- runif(15068,0,1)
    C<-NULL #save some memory space
```

Part a.

How large (bytes) are A and B?  Without any optimization tricks, how long does the it take to calculate y?  

***

### My Answer:

```{r, eval = F}
# Calculate y
    
# Without trick
system.time({
  y <- p + A %*% solve(B) %*% (q - r)
})
```

A is 107.1 Mb, whereas B is 1.7 Gb. I was unable to even calculate the amount of time it takes to calculate $y$ because of the error I get:  

Error: cannot allocate vector of size 1.7 Gb.  

***

&nbsp; 

Part b.

How would you break apart this compute, i.e., what order of operations would make sense?  Are there any mathmatical simplifications you can make?  Is there anything about the vectors or matrices we might take advantage of?

***

### My Answer:

Note that $B$ is an identity matrix. Since $B = I$, then $B^{-1} = I$ as well. Therefore, there is no reason to even have a $B$ in this formula. We solve for $y$:  

$y = p + AB^{-1} (q - r)$  
$y = p + A(q - r)$.  

This is much easier (and faster) to calculate.  

***

&nbsp; 

Part c.

Use ANY means (ANY package, ANY trick, etc) necessary to compute the above, fast.  Wrap your code in "system.time({})", everything you do past assignment "C <- NULL".

***

### My Answer:

```{r y reduced time, echo = T, eval = T, include = T, tidy = F}
system.time({
  y <- p + A %*% solve(B, (q - r))
})

system.time({
  y <- p + A %*% (q - r)
})
```

First, I start with the basic fix - using $Ax = b$ method instead of finding inverse of B matrix directly. 

The system.time() function gave us the following time stamps: 

User: 864.66  
System: 4.01  
Elapsed: 870.31.  

This is not that good but at least I could solve for y, unlike in part (a). 

Getting rid of the B matrix altogether gave us the following time stamps:

User: 1.08  
System: 1.84  
Elapsed: 24.97.  

While this may not appear to be too good, it is definitely better than "Error". So I will take it. 

***

&nbsp; 

## Problem 6

Push your homework as usual.

**When it is time to submit, --ONLY-- submit the .Rmd and .nb.html solution files.  Names should be formatted HW#_lastname_firstname.Rmd**

## Optional preperation for next class:  

Next week we will talk about the apply family of functions... swirl?

